{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5f650c-a3ff-41cb-84a0-d143c7844eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05bda745-98b8-4b5d-838e-ad3caafbd0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_descriptor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e79e95-01f0-4b95-85ae-913949acfd23",
   "metadata": {},
   "source": [
    "# Defines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7db4b-f002-469e-b022-94386359dd10",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b09704a-15bb-4e2c-b935-84df5faf14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "device = accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3917fddd-bba3-4777-a354-fc2c240beda7",
   "metadata": {},
   "outputs": [],
   "source": "bucket = \"\""
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b13020-7558-4b65-94b1-d978e5f76778",
   "metadata": {},
   "outputs": [],
   "source": "s3_output_path = \"\""
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a7ead0-4550-4dc1-a07e-782c51469ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_s3_key = \"interpro/processed/data_sample/esm_embeddings.h5\"\n",
    "embeddings_dir = \"/mnt/sagemaker-nvme/esm/data/processed/\"\n",
    "embeddings_path = os.path.join(embeddings_dir, \"esm_embeddings.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f1c03b-5f60-4397-a80e-10d687836f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(embeddings_path).is_file():\n",
    "    os.makedirs(embeddings_dir, exist_ok=True)\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.download_file(bucket, embeddings_s3_key, embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448da49a-7210-4b71-8bec-fcb5dbdf7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "train_frac = 0.8\n",
    "test_frac = 0.5\n",
    "\n",
    "model_save_dir = \"model_save\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24338f7c-acdd-4ee2-9c11-9704a42dae23",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f0696c-4a08-4194-b048-3a85c4ce411d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class InterProDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_proteinipr: pd.DataFrame,\n",
    "        embeddings_path: str,\n",
    "        index: pd.Index | None = None\n",
    "    ):\n",
    "        self.df_proteinipr = df_proteinipr\n",
    "        self.embeddings_path = embeddings_path\n",
    "        self.protein_embeddings = None\n",
    "\n",
    "        if index is None:\n",
    "            self.index = self.df_proteinipr.index\n",
    "        else:\n",
    "            self.index = index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        idx = self.index[idx]\n",
    "\n",
    "        if self.protein_embeddings is None:\n",
    "            self.protein_embeddings = h5py.File(self.embeddings_path, \"r\")[\"protein_embeddings\"]\n",
    "        # Features - ESM protein embeddings\n",
    "        x = torch.from_numpy(self.protein_embeddings[idx])\n",
    "\n",
    "        # Labels\n",
    "        y = torch.zeros(x.shape[0], dtype=torch.long)\n",
    "        # TODO this only supports the demo case of working with just IPR004839 (or any other single InterPro ID)\n",
    "        y_start, y_end = self.df_proteinipr.iloc[idx][\"start\"] + 1, self.df_proteinipr.iloc[idx][\"end\"] + 1\n",
    "        y[y_start:y_end] = 1\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e887511-7a47-448e-ba07-485ccb774e0a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class InterProModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_layers: int,\n",
    "        d_model: int,\n",
    "        d_ff: int = 2048,\n",
    "        n_heads: int = 4,\n",
    "        dropout: float = 0.1,\n",
    "        activation: str = \"gelu\",\n",
    "        output_dim: int = 2\n",
    "    ):\n",
    "        super(InterProModel, self).__init__()\n",
    "\n",
    "        if activation == \"gelu\":\n",
    "            output_activation = nn.GELU()\n",
    "        elif activation == \"relu\":\n",
    "            output_activation = nn.ReLU()\n",
    "        else:\n",
    "            raise RuntimeError(f\"activation should be relu/gelu, not {activation}\")\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                nn.LayerNorm(d_model)\n",
    "            ] + \\\n",
    "            [\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model=d_model,\n",
    "                    nhead=n_heads,\n",
    "                    dim_feedforward=d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            output_activation,\n",
    "            nn.Linear(d_model // 2, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "268252a0-34d3-4af2-94ac-dbe95e682ad6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class InterProModelTrainer:\n",
    "    def __init__(self, device: str | None = None):\n",
    "        self.accelerator = Accelerator()\n",
    "        self.device = device or self.accelerator.device\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        model: InterProModel,\n",
    "        train_loader: torch.utils.data.DataLoader,\n",
    "        epochs: int = 1,\n",
    "        lr: float = 1e-4,\n",
    "        val_loader: torch.utils.data.DataLoader | None = None,\n",
    "        checkpoint_metric: str = \"val_acc\",\n",
    "        checkpoint_mode: str = \"max\",\n",
    "        output_dir: str = \"./checkpoints\"\n",
    "    ):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Prepare objects with accelerator\n",
    "        model, optimizer, train_loader = self.accelerator.prepare(model, optimizer, train_loader)\n",
    "        if val_loader is not None:\n",
    "            val_loader = self.accelerator.prepare(val_loader)\n",
    "\n",
    "        best_metric = -float(\"inf\") if checkpoint_mode == \"max\" else float(\"inf\")\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            n_batches = 0\n",
    "\n",
    "            # Training loop with tqdm progress bar\n",
    "            train_pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "            for batch in train_pbar:\n",
    "                inputs, targets = batch\n",
    "                outputs = model(inputs)\n",
    "                # Swapping time and class axes for nn.CrossEntropyLoss()\n",
    "                loss = criterion(torch.swapaxes(outputs, -1, -2), targets)\n",
    "                optimizer.zero_grad()\n",
    "                self.accelerator.backward(loss)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                n_batches += 1\n",
    "                train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "            avg_train_loss = running_loss / n_batches if n_batches > 0 else 0.0\n",
    "            logging.info(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "            # Evaluate on val set if provided\n",
    "            if val_loader is not None:\n",
    "                model.eval()\n",
    "                total_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    val_pbar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
    "                    for batch in val_pbar:\n",
    "                        inputs, targets = batch\n",
    "                        outputs = model(inputs)\n",
    "                        # Swapping time and class axes for nn.CrossEntropyLoss()\n",
    "                        loss = criterion(torch.swapaxes(outputs, -1, -2), targets)\n",
    "                        total_loss += loss.item() * targets.size(0)\n",
    "\n",
    "                        preds = outputs.argmax(dim=-1)\n",
    "                        correct += (preds == targets).sum().item()\n",
    "                        total += targets.shape.numel()\n",
    "                    avg_val_loss = total_loss / total if total > 0 else 0.0\n",
    "                    accuracy = correct / total if total > 0 else 0.0\n",
    "                logging.info(\n",
    "                    f\"Epoch {epoch + 1}/{epochs} - Validation Loss: {avg_val_loss:.4f}, \"\n",
    "                    f\"Validation Accuracy: {accuracy:.4f}\"\n",
    "                )\n",
    "\n",
    "                # Checkpoint based on metric improvement (using val accuracy here)\n",
    "                current_metric = accuracy\n",
    "                improved = (current_metric > best_metric) if checkpoint_mode == \"max\" \\\n",
    "                    else (current_metric < best_metric)\n",
    "                if improved:\n",
    "                    best_metric = current_metric\n",
    "                    best_path = os.path.join(output_dir, \"best_checkpoint.pt\")\n",
    "                    if self.accelerator.is_main_process:\n",
    "                        torch.save(model.state_dict(), best_path)\n",
    "                        logging.info(\n",
    "                            f\"Saved new best checkpoint at epoch {epoch + 1} \"\n",
    "                            f\"with {checkpoint_metric}: {current_metric:.4f}\"\n",
    "                        )\n",
    "\n",
    "            # Save checkpoint at end of epoch\n",
    "            epoch_checkpoint = os.path.join(output_dir, f\"checkpoint_epoch_{epoch + 1}.pt\")\n",
    "            if self.accelerator.is_main_process:\n",
    "                torch.save(model.state_dict(), epoch_checkpoint)\n",
    "                logging.info(f\"Saved checkpoint for epoch {epoch + 1}\")\n",
    "\n",
    "        # Save final checkpoint\n",
    "        final_path = os.path.join(output_dir, \"final_checkpoint.pt\")\n",
    "        if self.accelerator.is_main_process:\n",
    "            torch.save(model.state_dict(), final_path)\n",
    "            logging.info(\"Saved final checkpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530cc0f-d1b1-4a89-90b5-fe81cc126bc5",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f960ff8-1aa6-41ab-8c9b-829af5b583da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    os.path.join(s3_output_path, \"proteinipr_with_sequences.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96f24b0e-2be4-461d-a76f-2a43acc67653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32668393333333334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only \"moderately\" imbalanced\n",
    "((df['end'] - df['start']) / 1000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc94e7d-d826-4537-80f6-b6191840cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, train_size=train_frac, random_state=random_state)\n",
    "df_val, df_test = train_test_split(df_val, train_size=test_frac, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "970ca2d2-8c40-4c1a-b729-8e14c6a33eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = InterProDataset(\n",
    "    df_proteinipr=df,\n",
    "    embeddings_path=embeddings_path,\n",
    "    index=df_train.index\n",
    ")\n",
    "ds_val = InterProDataset(\n",
    "    df_proteinipr=df,\n",
    "    embeddings_path=embeddings_path,\n",
    "    index=df_val.index\n",
    ")\n",
    "ds_test = InterProDataset(\n",
    "    df_proteinipr=df,\n",
    "    embeddings_path=embeddings_path,\n",
    "    index=df_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e54d263-df86-4c1b-a9b2-76f1e612dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(\n",
    "    dataset=ds_train,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "dl_val = DataLoader(\n",
    "    dataset=ds_val,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "dl_test = DataLoader(\n",
    "    dataset=ds_test,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc566729-ec34-40ba-ade4-2417b7d7e3ea",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb23d155-5b7b-41f2-89d0-aec47ce1d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c157da52-a122-44d2-addf-d507d6400b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InterProModel(\n",
    "    n_layers=2,\n",
    "    d_model=inputs.shape[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1fa396-7383-48a7-8416-c4e7de6f6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = InterProModelTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91e7f3c7-72bc-4be4-9b48-843a1b7b9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "cur_output_dir = os.path.join(model_save_dir, current_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c7010ed-3042-4691-81fe-20de573c48b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9aab5c2086478a9f89b9bbdc6619cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913c4928d451400a8331767941bf6f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 1/3 - Training Loss: 0.0724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b02a4d6792a4057b3c9cb9aa828e9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 1/3 - Validation Loss: 0.0000, Validation Accuracy: 0.9837\n",
      "INFO:root:Saved new best checkpoint at epoch 1 with val_acc: 0.9837\n",
      "INFO:root:Saved checkpoint for epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d253a974cb9f45a89d45edd239a1429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 2/3 - Training Loss: 0.0445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbae4144060047509c50fe89573d05cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 2/3 - Validation Loss: 0.0000, Validation Accuracy: 0.9849\n",
      "INFO:root:Saved new best checkpoint at epoch 2 with val_acc: 0.9849\n",
      "INFO:root:Saved checkpoint for epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bc434d293e48579c840a839f3ec121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 3/3 - Training Loss: 0.0400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31def63dc7174736b4ad3fc6211d3e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 3/3 - Validation Loss: 0.0000, Validation Accuracy: 0.9847\n",
      "INFO:root:Saved checkpoint for epoch 3\n",
      "INFO:root:Saved final checkpoint.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    model=model,\n",
    "    train_loader=dl_train,\n",
    "    val_loader=dl_val,\n",
    "    output_dir=cur_output_dir,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e58dc2-fc26-4e4e-8da3-385ed04dc569",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d8bef1c-3302-480f-b049-7cc7b711dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_dict = torch.load(\n",
    "    os.path.join(cur_output_dir, \"best_checkpoint.pt\"),\n",
    "    weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92dab58b-5017-4982-8040-3741b0333da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ddacbe9-3f75-45d7-86ad-91c0baed3ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = best_model.state_dict()\n",
    "model_dict.update(best_model_dict)\n",
    "best_model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c92a7181-9e54-435b-813e-cebe8f380a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize counters for each class (binary: class 0 and class 1)\n",
    "tp = [0, 0]  # true positives\n",
    "fp = [0, 0]  # false positives\n",
    "fn = [0, 0]  # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8d09d20-87c9-4d15-8022-a2db01242c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3800c618e54565a5820b4546e85dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test Loss: 0.0000, Test Accuracy: 0.9862, Precision: [0.9914733976777852, 0.9754123168433498], Recall: [0.9879108102316648, 0.9825932128977707]\n"
     ]
    }
   ],
   "source": [
    "best_model, dl_test = trainer.accelerator.prepare(best_model, dl_test)\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_pbar = tqdm(dl_test, desc=\"Test\", leave=False)\n",
    "    \n",
    "    for batch in val_pbar:\n",
    "        inputs, targets = batch\n",
    "        outputs = best_model(inputs)\n",
    "        # Swapping time and class axes for nn.CrossEntropyLoss()\n",
    "        loss = criterion(torch.swapaxes(outputs, -1, -2), targets)\n",
    "        total_loss += loss.item() * targets.size(0)\n",
    "    \n",
    "        preds = outputs.argmax(dim=-1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.numel()\n",
    "    \n",
    "        # Update per-class counters\n",
    "        for cls in [0, 1]:\n",
    "            tp[cls] += ((preds == cls) & (targets == cls)).sum().item()\n",
    "            fp[cls] += ((preds == cls) & (targets != cls)).sum().item()\n",
    "            fn[cls] += ((preds != cls) & (targets == cls)).sum().item()\n",
    "\n",
    "avg_test_loss = total_loss / total if total > 0 else 0.0\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "\n",
    "# Compute precision and recall for each class\n",
    "precision = [tp[i] / (tp[i] + fp[i]) if (tp[i] + fp[i]) > 0 else 0.0 for i in [0, 1]]\n",
    "recall    = [tp[i] / (tp[i] + fn[i]) if (tp[i] + fn[i]) > 0 else 0.0 for i in [0, 1]]\n",
    "\n",
    "logging.info(\n",
    "    f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "    f\"Test Accuracy: {accuracy:.4f}, \"\n",
    "    f\"Precision: {precision}, \"\n",
    "    f\"Recall: {recall}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
